<!doctype html>
<!--
  Minimal Mistakes Jekyll Theme 4.12.0 by Michael Rose
  Copyright 2013-2018 Michael Rose - mademistakes.com | @mmistakes
  Free for personal and commercial use under the MIT license
  https://github.com/mmistakes/minimal-mistakes/blob/master/LICENSE.txt
-->
<html lang="ko" class="no-js">
  <head>
    <meta charset="utf-8">

<!-- begin _includes/seo.html --><title>LSTM with Attention - Inspiring People</title>
<meta name="description" content="attention with LSTM을 통한 keras 딥러닝 기법">



<meta property="og:type" content="article">
<meta property="og:locale" content="ko">
<meta property="og:site_name" content="Inspiring People">
<meta property="og:title" content="LSTM with Attention">
<meta property="og:url" content="http://localhost:4000/data%20analysis/lstm_attention/">


  <meta property="og:description" content="attention with LSTM을 통한 keras 딥러닝 기법">



  <meta property="og:image" content="http://localhost:4000/assets/img/teaser.png">





  <meta property="article:published_time" content="2018-03-07T00:00:00+09:00">





  

  


<link rel="canonical" href="http://localhost:4000/data%20analysis/lstm_attention/">





  <script type="application/ld+json">
    {
      "@context": "http://schema.org",
      "@type": "Organization",
      "url": "http://localhost:4000",
      "logo": "http://localhost:4000/assets/img/teaser.png"
    }
  </script>



  <script type="application/ld+json">
    {
      "@context": "http://schema.org",
      "@type": "Person",
      "name": "YounKyung Jang",
      "url": "http://localhost:4000",
      "sameAs": null
    }
  </script>







<!-- end _includes/seo.html -->


<link href="/feed.xml" type="application/atom+xml" rel="alternate" title="Inspiring People Feed">

<!-- http://t.co/dKP3o1e -->
<meta name="HandheldFriendly" content="True">
<meta name="MobileOptimized" content="320">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="/assets/css/main.css">

<!--[if lte IE 9]>
  <style>
    /* old IE unsupported flexbox fixes */
    .greedy-nav .site-title {
      padding-right: 3em;
    }
    .greedy-nav button {
      position: absolute;
      top: 0;
      right: 0;
      height: 100%;
    }
  </style>
<![endif]-->


    <!-- start custom head snippets -->

<!-- insert favicons. use https://realfavicongenerator.net/ -->

<!-- end custom head snippets -->

  </head>

  <body class="layout--single">

    <!--[if lt IE 9]>
<div class="notice--danger align-center" style="margin: 0;">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience.</div>
<![endif]-->

    <div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        <a class="site-title" href="/">Inspiring People</a>
        <ul class="visible-links">
          
            
            <li class="masthead__menu-item">
              <a href="http://localhost:4000/categories/" >Category</a>
            </li>
          
            
            <li class="masthead__menu-item">
              <a href="http://localhost:4000/tags/" >Tag</a>
            </li>
          
            
            <li class="masthead__menu-item">
              <a href="http://localhost:4000/archive/" >Archive</a>
            </li>
          
        </ul>
        
        <button class="search__toggle" type="button">
          <svg class="icon" width="16" height="16" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 15.99 16">
            <path d="M15.5,13.12L13.19,10.8a1.69,1.69,0,0,0-1.28-.55l-0.06-.06A6.5,6.5,0,0,0,5.77,0,6.5,6.5,0,0,0,2.46,11.59a6.47,6.47,0,0,0,7.74.26l0.05,0.05a1.65,1.65,0,0,0,.5,1.24l2.38,2.38A1.68,1.68,0,0,0,15.5,13.12ZM6.4,2A4.41,4.41,0,1,1,2,6.4,4.43,4.43,0,0,1,6.4,2Z" transform="translate(-.01)"></path>
          </svg>
        </button>
        
        <button class="greedy-nav__toggle hidden" type="button">
          <span class="visually-hidden">토글 메뉴</span>
          <div class="navicon"></div>
        </button>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>

    <div class="initial-content">
      



<div id="main" role="main">
  
  <div class="sidebar sticky">
  


<div itemscope itemtype="http://schema.org/Person">

  
    <div class="author__avatar">
      

      
        <img src="/assets/img/profile.jpg" alt="YounKyung Jang" itemprop="image">
      
    </div>
  

  <div class="author__content">
    
      <h3 class="author__name" itemprop="name">YounKyung Jang</h3>
    
    
      <p class="author__bio" itemprop="description">
        자세히 보아야 아름답다. 너도 그렇다
      </p>
    
  </div>

  <div class="author__urls-wrapper">
    <button class="btn btn--inverse">팔로우</button>
    <ul class="author__urls social-icons">
      

      

      
        <li>
          <a href="mailto:ykjang@gmail.com">
            <meta itemprop="email" content="ykjang@gmail.com" />
            <i class="fas fa-fw fa-envelope-square" aria-hidden="true"></i> 이메일
          </a>
        </li>
      

      

      

      

      

      

      

      

      

      

      
        <li>
          <a href="https://github.com/InspiringPeople" itemprop="sameAs">
            <i class="fab fa-fw fa-github" aria-hidden="true"></i> GitHub
          </a>
        </li>
      

      

      

      

      

      

      

      

      
        
          <li>
            <a href="https://youtube.com/dearpiano" itemprop="sameAs">
              <i class="fab fa-fw fa-youtube" aria-hidden="true"></i> YouTube
            </a>
          </li>
        
      

      

      

      

      

      

      <!--
  <li>
    <a href="http://link-to-whatever-social-network.com/user/" itemprop="sameAs">
      <i class="fas fa-fw" aria-hidden="true"></i> Custom Social Profile Link
    </a>
  </li>
-->
    </ul>
  </div>  

  
    <div class="author__avatar2">
      

      
        <img src="/assets/img/profile2.jpg" alt="YounKyung Jang" itemprop="image">
      
    </div>
  
</div>

  
  </div>


  <article class="page" itemscope itemtype="http://schema.org/CreativeWork">
    <meta itemprop="headline" content="LSTM with Attention">
    <meta itemprop="description" content="attention with LSTM을 통한 keras 딥러닝 기법">
    <meta itemprop="datePublished" content="March 07, 2018">
    

    <div class="page__inner-wrap">
      
        <header>
          <h1 class="page__title" itemprop="headline">LSTM with Attention
</h1>
          
        </header>
      

      <section class="page__content" itemprop="text">
        
          <aside class="sidebar__right">
            <nav class="toc">
              <header><h4 class="nav__title"><i class="fas fa-file-alt"></i> On This Page</h4></header>
              
            </nav>
          </aside>
        
        <p>attention with LSTM을 통한 keras 딥러닝 기법</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="s">'''
Single model may achieve LB scores at around 0.043
Don't need to be an expert of feature engineering
All you need is a GPU!!!!!!!

The code is tested on Keras 2.0.0 using Theano backend, and Python 3.5

referrence Code:https://www.kaggle.com/lystdo/lstm-with-word2vec-embeddings
'''</span>

<span class="c">########################################</span>
<span class="c">## import packages</span>
<span class="c">########################################</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">re</span>
<span class="kn">import</span> <span class="nn">csv</span>
<span class="kn">import</span> <span class="nn">codecs</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>

<span class="kn">from</span> <span class="nn">nltk.corpus</span> <span class="kn">import</span> <span class="n">stopwords</span>
<span class="kn">from</span> <span class="nn">nltk.stem</span> <span class="kn">import</span> <span class="n">SnowballStemmer</span>
<span class="kn">from</span> <span class="nn">string</span> <span class="kn">import</span> <span class="n">punctuation</span>

<span class="kn">from</span> <span class="nn">gensim.models</span> <span class="kn">import</span> <span class="n">KeyedVectors</span>
<span class="kn">from</span> <span class="nn">keras.preprocessing.text</span> <span class="kn">import</span> <span class="n">Tokenizer</span>
<span class="kn">from</span> <span class="nn">keras.preprocessing.sequence</span> <span class="kn">import</span> <span class="n">pad_sequences</span>
<span class="kn">from</span> <span class="nn">keras.layers</span> <span class="kn">import</span> <span class="n">Dense</span><span class="p">,</span> <span class="n">Input</span><span class="p">,</span> <span class="n">LSTM</span><span class="p">,</span> <span class="n">Embedding</span><span class="p">,</span> <span class="n">Dropout</span><span class="p">,</span> <span class="n">Activation</span>
<span class="kn">from</span> <span class="nn">keras.layers.merge</span> <span class="kn">import</span> <span class="n">concatenate</span>
<span class="kn">from</span> <span class="nn">keras.models</span> <span class="kn">import</span> <span class="n">Model</span>
<span class="kn">from</span> <span class="nn">keras.layers.normalization</span> <span class="kn">import</span> <span class="n">BatchNormalization</span>
<span class="kn">from</span> <span class="nn">keras.callbacks</span> <span class="kn">import</span> <span class="n">EarlyStopping</span><span class="p">,</span> <span class="n">ModelCheckpoint</span>




<span class="kn">import</span> <span class="nn">sys</span>

</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>/home/younkyung.jang/miniconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">########################################</span>
<span class="c">## set directories and parameters</span>
<span class="c">########################################</span>



<span class="kn">from</span> <span class="nn">keras</span> <span class="kn">import</span> <span class="n">backend</span> <span class="k">as</span> <span class="n">K</span>
<span class="kn">from</span> <span class="nn">keras.engine.topology</span> <span class="kn">import</span> <span class="n">Layer</span>
<span class="c">#from keras import initializations</span>
<span class="kn">from</span> <span class="nn">keras</span> <span class="kn">import</span> <span class="n">initializers</span><span class="p">,</span> <span class="n">regularizers</span><span class="p">,</span> <span class="n">constraints</span>


<span class="k">class</span> <span class="nc">Attention</span><span class="p">(</span><span class="n">Layer</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">step_dim</span><span class="p">,</span>
                 <span class="n">W_regularizer</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">b_regularizer</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
                 <span class="n">W_constraint</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">b_constraint</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
                 <span class="n">bias</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="s">"""
        Keras Layer that implements an Attention mechanism for temporal data.
        Supports Masking.
        Follows the work of Raffel et al. [https://arxiv.org/abs/1512.08756]
        # Input shape
            3D tensor with shape: `(samples, steps, features)`.
        # Output shape
            2D tensor with shape: `(samples, features)`.
        :param kwargs:
        Just put it on top of an RNN Layer (GRU/LSTM/SimpleRNN) with return_sequences=True.
        The dimensions are inferred based on the output shape of the RNN.
        Example:
            model.add(LSTM(64, return_sequences=True))
            model.add(Attention())
        """</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">supports_masking</span> <span class="o">=</span> <span class="bp">True</span>
        <span class="c">#self.init = initializations.get('glorot_uniform')</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">init</span> <span class="o">=</span> <span class="n">initializers</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s">'glorot_uniform'</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">W_regularizer</span> <span class="o">=</span> <span class="n">regularizers</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">W_regularizer</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">b_regularizer</span> <span class="o">=</span> <span class="n">regularizers</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">b_regularizer</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">W_constraint</span> <span class="o">=</span> <span class="n">constraints</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">W_constraint</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">b_constraint</span> <span class="o">=</span> <span class="n">constraints</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">b_constraint</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">bias</span> <span class="o">=</span> <span class="n">bias</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">step_dim</span> <span class="o">=</span> <span class="n">step_dim</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">features_dim</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Attention</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">build</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_shape</span><span class="p">):</span>
        <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">input_shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">3</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">W</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">add_weight</span><span class="p">((</span><span class="n">input_shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],),</span>
                                 <span class="n">initializer</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">init</span><span class="p">,</span>
                                 <span class="n">name</span><span class="o">=</span><span class="s">'{}_W'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">name</span><span class="p">),</span>
                                 <span class="n">regularizer</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">W_regularizer</span><span class="p">,</span>
                                 <span class="n">constraint</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">W_constraint</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">features_dim</span> <span class="o">=</span> <span class="n">input_shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">b</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">add_weight</span><span class="p">((</span><span class="n">input_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],),</span>
                                     <span class="n">initializer</span><span class="o">=</span><span class="s">'zero'</span><span class="p">,</span>
                                     <span class="n">name</span><span class="o">=</span><span class="s">'{}_b'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">name</span><span class="p">),</span>
                                     <span class="n">regularizer</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">b_regularizer</span><span class="p">,</span>
                                     <span class="n">constraint</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">b_constraint</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">b</span> <span class="o">=</span> <span class="bp">None</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">built</span> <span class="o">=</span> <span class="bp">True</span>

    <span class="k">def</span> <span class="nf">compute_mask</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">,</span> <span class="n">input_mask</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="c"># do not pass the mask to the next layers</span>
        <span class="k">return</span> <span class="bp">None</span>

    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">mask</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="c"># eij = K.dot(x, self.W) TF backend doesn't support it</span>

        <span class="c"># features_dim = self.W.shape[0]</span>
        <span class="c"># step_dim = x._keras_shape[1]</span>

        <span class="n">features_dim</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">features_dim</span>
        <span class="n">step_dim</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">step_dim</span>

        <span class="n">eij</span> <span class="o">=</span> <span class="n">K</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">K</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">K</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">features_dim</span><span class="p">)),</span> <span class="n">K</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">W</span><span class="p">,</span> <span class="p">(</span><span class="n">features_dim</span><span class="p">,</span> <span class="mi">1</span><span class="p">))),</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">step_dim</span><span class="p">))</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias</span><span class="p">:</span>
            <span class="n">eij</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">b</span>

        <span class="n">eij</span> <span class="o">=</span> <span class="n">K</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">eij</span><span class="p">)</span>

        <span class="n">a</span> <span class="o">=</span> <span class="n">K</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">eij</span><span class="p">)</span>

        <span class="c"># apply mask after the exp. will be re-normalized next</span>
        <span class="k">if</span> <span class="n">mask</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
            <span class="c"># Cast the mask to floatX to avoid float64 upcasting in theano</span>
            <span class="n">a</span> <span class="o">*=</span> <span class="n">K</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">mask</span><span class="p">,</span> <span class="n">K</span><span class="o">.</span><span class="n">floatx</span><span class="p">())</span>

        <span class="c"># in some cases especially in the early stages of training the sum may be almost zero</span>
        <span class="n">a</span> <span class="o">/=</span> <span class="n">K</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">K</span><span class="o">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span> <span class="o">+</span> <span class="n">K</span><span class="o">.</span><span class="n">epsilon</span><span class="p">(),</span> <span class="n">K</span><span class="o">.</span><span class="n">floatx</span><span class="p">())</span>

        <span class="n">a</span> <span class="o">=</span> <span class="n">K</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
        <span class="n">weighted_input</span> <span class="o">=</span> <span class="n">x</span> <span class="o">*</span> <span class="n">a</span>
    <span class="c">#print weigthted_input.shape</span>
        <span class="k">return</span> <span class="n">K</span><span class="o">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">weighted_input</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">compute_output_shape</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_shape</span><span class="p">):</span>
        <span class="c">#return input_shape[0], input_shape[-1]</span>
        <span class="k">return</span> <span class="n">input_shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>  <span class="bp">self</span><span class="o">.</span><span class="n">features_dim</span>
        
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">path</span> <span class="o">=</span> <span class="s">'./input/'</span> <span class="c">#yk</span>
<span class="n">EMBEDDING_FILE</span><span class="o">=</span><span class="n">path</span><span class="o">+</span><span class="s">'glove.840B.300d.txt'</span>
<span class="n">TRAIN_DATA_FILE</span><span class="o">=</span><span class="n">path</span><span class="o">+</span><span class="s">'train.csv'</span>
<span class="n">TEST_DATA_FILE</span><span class="o">=</span><span class="n">path</span><span class="o">+</span><span class="s">'test.csv'</span>

<span class="n">MAX_SEQUENCE_LENGTH</span> <span class="o">=</span> <span class="mi">150</span>
<span class="n">MAX_NB_WORDS</span> <span class="o">=</span> <span class="mi">100000</span>
<span class="n">EMBEDDING_DIM</span> <span class="o">=</span> <span class="mi">300</span>
<span class="n">VALIDATION_SPLIT</span> <span class="o">=</span> <span class="mf">0.1</span>

<span class="n">num_lstm</span> <span class="o">=</span> <span class="mi">300</span>
<span class="n">num_dense</span> <span class="o">=</span> <span class="mi">256</span>
<span class="n">rate_drop_lstm</span> <span class="o">=</span> <span class="mf">0.25</span>
<span class="n">rate_drop_dense</span> <span class="o">=</span> <span class="mf">0.25</span>

<span class="n">act</span> <span class="o">=</span> <span class="s">'relu'</span>

</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">########################################</span>
<span class="c">## index word vectors</span>
<span class="c">########################################</span>
<span class="k">print</span><span class="p">(</span><span class="s">'Indexing word vectors'</span><span class="p">)</span>

<span class="c">#Glove Vectors</span>
<span class="n">embeddings_index</span> <span class="o">=</span> <span class="p">{}</span>
<span class="n">f</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="n">EMBEDDING_FILE</span><span class="p">)</span>
<span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">values</span> <span class="o">=</span> <span class="n">line</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>
    <span class="c">#word = values[0] #yk</span>
    <span class="c">#coefs = np.asarray(values[1:], dtype='float32')  #yk</span>
    <span class="n">word</span> <span class="o">=</span> <span class="s">' '</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">values</span><span class="p">[:</span><span class="o">-</span><span class="mi">300</span><span class="p">])</span>
    <span class="n">coefs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">values</span><span class="p">[</span><span class="o">-</span><span class="mi">300</span><span class="p">:],</span> <span class="n">dtype</span><span class="o">=</span><span class="s">'float32'</span><span class="p">)</span>
    <span class="n">embeddings_index</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">=</span> <span class="n">coefs</span>
<span class="n">f</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>

<span class="k">print</span><span class="p">(</span><span class="s">'Total </span><span class="si">%</span><span class="s">s word vectors.'</span> <span class="o">%</span> <span class="nb">len</span><span class="p">(</span><span class="n">embeddings_index</span><span class="p">))</span>

<span class="n">train_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">TRAIN_DATA_FILE</span><span class="p">)</span>
<span class="n">test_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">TEST_DATA_FILE</span><span class="p">)</span>

</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Indexing word vectors
Total 2195895 word vectors.
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">########################################</span>
<span class="c">## process texts in datasets</span>
<span class="c">########################################</span>
<span class="k">print</span><span class="p">(</span><span class="s">'Processing text dataset'</span><span class="p">)</span>

<span class="c">#Regex to remove all Non-Alpha Numeric and space</span>
<span class="n">special_character_removal</span><span class="o">=</span><span class="n">re</span><span class="o">.</span><span class="nb">compile</span><span class="p">(</span><span class="s">r'[^a-z\d ]'</span><span class="p">,</span><span class="n">re</span><span class="o">.</span><span class="n">IGNORECASE</span><span class="p">)</span>

<span class="c">#regex to replace all numerics</span>
<span class="n">replace_numbers</span><span class="o">=</span><span class="n">re</span><span class="o">.</span><span class="nb">compile</span><span class="p">(</span><span class="s">r'\d+'</span><span class="p">,</span><span class="n">re</span><span class="o">.</span><span class="n">IGNORECASE</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">text_to_wordlist</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">remove_stopwords</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">stem_words</span><span class="o">=</span><span class="bp">False</span><span class="p">):</span>
    <span class="c"># Clean the text, with the option to remove stopwords and to stem words.</span>
    
    <span class="c"># Convert words to lower case and split them</span>
    <span class="n">text</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>

    <span class="c"># Optionally, remove stop words</span>
    <span class="k">if</span> <span class="n">remove_stopwords</span><span class="p">:</span>
        <span class="n">stops</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">stopwords</span><span class="o">.</span><span class="n">words</span><span class="p">(</span><span class="s">"english"</span><span class="p">))</span>
        <span class="n">text</span> <span class="o">=</span> <span class="p">[</span><span class="n">w</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">text</span> <span class="k">if</span> <span class="ow">not</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">stops</span><span class="p">]</span>
    
    <span class="n">text</span> <span class="o">=</span> <span class="s">" "</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
    
    <span class="c">#Remove Special Characters</span>
    <span class="n">text</span><span class="o">=</span><span class="n">special_character_removal</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="s">''</span><span class="p">,</span><span class="n">text</span><span class="p">)</span>
    
    <span class="c">#Replace Numbers</span>
    <span class="n">text</span><span class="o">=</span><span class="n">replace_numbers</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="s">'n'</span><span class="p">,</span><span class="n">text</span><span class="p">)</span>

    <span class="c"># Optionally, shorten words to their stems</span>
    <span class="k">if</span> <span class="n">stem_words</span><span class="p">:</span>
        <span class="n">text</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>
        <span class="n">stemmer</span> <span class="o">=</span> <span class="n">SnowballStemmer</span><span class="p">(</span><span class="s">'english'</span><span class="p">)</span>
        <span class="n">stemmed_words</span> <span class="o">=</span> <span class="p">[</span><span class="n">stemmer</span><span class="o">.</span><span class="n">stem</span><span class="p">(</span><span class="n">word</span><span class="p">)</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">text</span><span class="p">]</span>
        <span class="n">text</span> <span class="o">=</span> <span class="s">" "</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">stemmed_words</span><span class="p">)</span>
    
    <span class="c"># Return a list of words</span>
    <span class="k">return</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>

</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Processing text dataset
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">list_sentences_train</span> <span class="o">=</span> <span class="n">train_df</span><span class="p">[</span><span class="s">"comment_text"</span><span class="p">]</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="s">"NA"</span><span class="p">)</span><span class="o">.</span><span class="n">values</span>
<span class="n">list_classes</span> <span class="o">=</span> <span class="p">[</span><span class="s">"toxic"</span><span class="p">,</span> <span class="s">"severe_toxic"</span><span class="p">,</span> <span class="s">"obscene"</span><span class="p">,</span> <span class="s">"threat"</span><span class="p">,</span> <span class="s">"insult"</span><span class="p">,</span> <span class="s">"identity_hate"</span><span class="p">]</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">train_df</span><span class="p">[</span><span class="n">list_classes</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>
<span class="n">list_sentences_test</span> <span class="o">=</span> <span class="n">test_df</span><span class="p">[</span><span class="s">"comment_text"</span><span class="p">]</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="s">"NA"</span><span class="p">)</span><span class="o">.</span><span class="n">values</span>


<span class="n">comments</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">text</span> <span class="ow">in</span> <span class="n">list_sentences_train</span><span class="p">:</span>
    <span class="n">comments</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">text_to_wordlist</span><span class="p">(</span><span class="n">text</span><span class="p">))</span>
    
<span class="n">test_comments</span><span class="o">=</span><span class="p">[]</span>
<span class="k">for</span> <span class="n">text</span> <span class="ow">in</span> <span class="n">list_sentences_test</span><span class="p">:</span>
    <span class="n">test_comments</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">text_to_wordlist</span><span class="p">(</span><span class="n">text</span><span class="p">))</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">Tokenizer</span><span class="p">(</span><span class="n">num_words</span><span class="o">=</span><span class="n">MAX_NB_WORDS</span><span class="p">)</span>
<span class="n">tokenizer</span><span class="o">.</span><span class="n">fit_on_texts</span><span class="p">(</span><span class="n">comments</span> <span class="o">+</span> <span class="n">test_comments</span><span class="p">)</span>

<span class="n">sequences</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">texts_to_sequences</span><span class="p">(</span><span class="n">comments</span><span class="p">)</span>
<span class="n">test_sequences</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">texts_to_sequences</span><span class="p">(</span><span class="n">test_comments</span><span class="p">)</span>

<span class="n">word_index</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">word_index</span>
<span class="k">print</span><span class="p">(</span><span class="s">'Found </span><span class="si">%</span><span class="s">s unique tokens'</span> <span class="o">%</span> <span class="nb">len</span><span class="p">(</span><span class="n">word_index</span><span class="p">))</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">pad_sequences</span><span class="p">(</span><span class="n">sequences</span><span class="p">,</span> <span class="n">maxlen</span><span class="o">=</span><span class="n">MAX_SEQUENCE_LENGTH</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'Shape of data tensor:'</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'Shape of label tensor:'</span><span class="p">,</span> <span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="n">test_data</span> <span class="o">=</span> <span class="n">pad_sequences</span><span class="p">(</span><span class="n">test_sequences</span><span class="p">,</span> <span class="n">maxlen</span><span class="o">=</span><span class="n">MAX_SEQUENCE_LENGTH</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'Shape of test_data tensor:'</span><span class="p">,</span> <span class="n">test_data</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Found 392183 unique tokens
Shape of data tensor: (159571, 150)
Shape of label tensor: (159571, 6)
Shape of test_data tensor: (153164, 150)
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">########################################</span>
<span class="c">## prepare embeddings</span>
<span class="c">########################################</span>
<span class="k">print</span><span class="p">(</span><span class="s">'Preparing embedding matrix'</span><span class="p">)</span>
<span class="n">nb_words</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">MAX_NB_WORDS</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">word_index</span><span class="p">))</span>
<span class="n">embedding_matrix</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">nb_words</span><span class="p">,</span> <span class="n">EMBEDDING_DIM</span><span class="p">))</span>
<span class="k">for</span> <span class="n">word</span><span class="p">,</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">word_index</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="k">if</span> <span class="n">i</span> <span class="o">&gt;=</span> <span class="n">MAX_NB_WORDS</span><span class="p">:</span>
        <span class="k">continue</span>
    <span class="n">embedding_vector</span> <span class="o">=</span> <span class="n">embeddings_index</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">embedding_vector</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
        <span class="c"># words not found in embedding index will be all-zeros.</span>
        <span class="n">embedding_matrix</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">embedding_vector</span>

<span class="k">print</span><span class="p">(</span><span class="s">'Null word embeddings: </span><span class="si">%</span><span class="s">d'</span> <span class="o">%</span> <span class="n">np</span><span class="o">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">embedding_matrix</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">))</span>

</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Preparing embedding matrix
Null word embeddings: 25722
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">########################################</span>
<span class="c">## sample train/validation data</span>
<span class="c">########################################</span>
<span class="c"># np.random.seed(1234)</span>
<span class="n">perm</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">permutation</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">))</span>
<span class="n">idx_train</span> <span class="o">=</span> <span class="n">perm</span><span class="p">[:</span><span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)</span><span class="o">*</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">VALIDATION_SPLIT</span><span class="p">))]</span>
<span class="n">idx_val</span> <span class="o">=</span> <span class="n">perm</span><span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)</span><span class="o">*</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">VALIDATION_SPLIT</span><span class="p">)):]</span>

<span class="n">data_train</span><span class="o">=</span><span class="n">data</span><span class="p">[</span><span class="n">idx_train</span><span class="p">]</span>
<span class="n">labels_train</span><span class="o">=</span><span class="n">y</span><span class="p">[</span><span class="n">idx_train</span><span class="p">]</span>
<span class="k">print</span><span class="p">(</span><span class="n">data_train</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span><span class="n">labels_train</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="n">data_val</span><span class="o">=</span><span class="n">data</span><span class="p">[</span><span class="n">idx_val</span><span class="p">]</span>
<span class="n">labels_val</span><span class="o">=</span><span class="n">y</span><span class="p">[</span><span class="n">idx_val</span><span class="p">]</span>

<span class="k">print</span><span class="p">(</span><span class="n">data_val</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span><span class="n">labels_val</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(143613, 150) (143613, 6)
(15958, 150) (15958, 6)
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">########################################</span>
<span class="c">## define the model structure</span>
<span class="c">########################################</span>
<span class="n">embedding_layer</span> <span class="o">=</span> <span class="n">Embedding</span><span class="p">(</span><span class="n">nb_words</span><span class="p">,</span>
        <span class="n">EMBEDDING_DIM</span><span class="p">,</span>
        <span class="n">weights</span><span class="o">=</span><span class="p">[</span><span class="n">embedding_matrix</span><span class="p">],</span>
        <span class="n">input_length</span><span class="o">=</span><span class="n">MAX_SEQUENCE_LENGTH</span><span class="p">,</span>
        <span class="n">trainable</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

<span class="n">lstm_layer</span> <span class="o">=</span> <span class="n">LSTM</span><span class="p">(</span><span class="n">num_lstm</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="n">rate_drop_lstm</span><span class="p">,</span> <span class="n">recurrent_dropout</span><span class="o">=</span><span class="n">rate_drop_lstm</span><span class="p">,</span><span class="n">return_sequences</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="n">comment_input</span> <span class="o">=</span> <span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">MAX_SEQUENCE_LENGTH</span><span class="p">,),</span> <span class="n">dtype</span><span class="o">=</span><span class="s">'int32'</span><span class="p">)</span>
<span class="n">embedded_sequences</span><span class="o">=</span> <span class="n">embedding_layer</span><span class="p">(</span><span class="n">comment_input</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">lstm_layer</span><span class="p">(</span><span class="n">embedded_sequences</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">Dropout</span><span class="p">(</span><span class="n">rate_drop_dense</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="n">merged</span> <span class="o">=</span> <span class="n">Attention</span><span class="p">(</span><span class="n">MAX_SEQUENCE_LENGTH</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="n">merged</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="n">num_dense</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">act</span><span class="p">)(</span><span class="n">merged</span><span class="p">)</span>
<span class="n">merged</span> <span class="o">=</span> <span class="n">Dropout</span><span class="p">(</span><span class="n">rate_drop_dense</span><span class="p">)(</span><span class="n">merged</span><span class="p">)</span>
<span class="n">merged</span> <span class="o">=</span> <span class="n">BatchNormalization</span><span class="p">()(</span><span class="n">merged</span><span class="p">)</span>
<span class="n">preds</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'sigmoid'</span><span class="p">)(</span><span class="n">merged</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">########################################</span>
<span class="c">## train the model</span>
<span class="c">########################################</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">comment_input</span><span class="p">],</span> \
        <span class="n">outputs</span><span class="o">=</span><span class="n">preds</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="nb">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s">'binary_crossentropy'</span><span class="p">,</span>
        <span class="n">optimizer</span><span class="o">=</span><span class="s">'rmsprop'</span><span class="p">,</span>
        <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s">'accuracy'</span><span class="p">])</span>
<span class="k">print</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">summary</span><span class="p">())</span>

<span class="n">STAMP</span> <span class="o">=</span> <span class="s">'simple_lstm_glove_vectors_</span><span class="si">%.2</span><span class="s">f_</span><span class="si">%.2</span><span class="s">f'</span><span class="o">%</span><span class="p">(</span><span class="n">rate_drop_lstm</span><span class="p">,</span><span class="n">rate_drop_dense</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">STAMP</span><span class="p">)</span>

<span class="n">early_stopping</span> <span class="o">=</span><span class="n">EarlyStopping</span><span class="p">(</span><span class="n">monitor</span><span class="o">=</span><span class="s">'val_loss'</span><span class="p">,</span> <span class="n">patience</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">bst_model_path</span> <span class="o">=</span> <span class="n">STAMP</span> <span class="o">+</span> <span class="s">'.h5'</span>
<span class="n">model_checkpoint</span> <span class="o">=</span> <span class="n">ModelCheckpoint</span><span class="p">(</span><span class="n">bst_model_path</span><span class="p">,</span> <span class="n">save_best_only</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">save_weights_only</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="n">hist</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data_train</span><span class="p">,</span> <span class="n">labels_train</span><span class="p">,</span> \
        <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">data_val</span><span class="p">,</span> <span class="n">labels_val</span><span class="p">),</span> \
        <span class="n">epochs</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> \
         <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">early_stopping</span><span class="p">,</span> <span class="n">model_checkpoint</span><span class="p">])</span>
         
<span class="n">model</span><span class="o">.</span><span class="n">load_weights</span><span class="p">(</span><span class="n">bst_model_path</span><span class="p">)</span>
<span class="n">bst_val_score</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">hist</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s">'val_loss'</span><span class="p">])</span>

</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 150)               0         
_________________________________________________________________
embedding_1 (Embedding)      (None, 150, 300)          30000000  
_________________________________________________________________
lstm_1 (LSTM)                (None, 150, 300)          721200    
_________________________________________________________________
dropout_1 (Dropout)          (None, 150, 300)          0         
_________________________________________________________________
attention_1 (Attention)      (None, 300)               450       
_________________________________________________________________
dense_1 (Dense)              (None, 256)               77056     
_________________________________________________________________
dropout_2 (Dropout)          (None, 256)               0         
_________________________________________________________________
batch_normalization_1 (Batch (None, 256)               1024      
_________________________________________________________________
dense_2 (Dense)              (None, 6)                 1542      
=================================================================
Total params: 30,801,272
Trainable params: 800,760
Non-trainable params: 30,000,512
_________________________________________________________________
None
simple_lstm_glove_vectors_0.25_0.25
Train on 143613 samples, validate on 15958 samples
Epoch 1/50
143613/143613 [==============================] - 142s 992us/step - loss: 0.0400 - acc: 0.9846 - val_loss: 0.0440 - val_acc: 0.9836
Epoch 2/50
143613/143613 [==============================] - 140s 973us/step - loss: 0.0387 - acc: 0.9849 - val_loss: 0.0445 - val_acc: 0.9838
Epoch 3/50
143613/143613 [==============================] - 142s 986us/step - loss: 0.0378 - acc: 0.9851 - val_loss: 0.0425 - val_acc: 0.9839
Epoch 4/50
143613/143613 [==============================] - 139s 971us/step - loss: 0.0366 - acc: 0.9856 - val_loss: 0.0426 - val_acc: 0.9840
Epoch 5/50
143613/143613 [==============================] - 140s 972us/step - loss: 0.0357 - acc: 0.9860 - val_loss: 0.0434 - val_acc: 0.9841
Epoch 6/50
143613/143613 [==============================] - 140s 977us/step - loss: 0.0347 - acc: 0.9863 - val_loss: 0.0444 - val_acc: 0.9838
Epoch 7/50
143613/143613 [==============================] - 139s 965us/step - loss: 0.0338 - acc: 0.9867 - val_loss: 0.0442 - val_acc: 0.9839
Epoch 8/50
143613/143613 [==============================] - 140s 973us/step - loss: 0.0326 - acc: 0.9870 - val_loss: 0.0449 - val_acc: 0.9840
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#######################################</span>
<span class="c">## make the submission</span>
<span class="c">########################################</span>
<span class="k">print</span><span class="p">(</span><span class="s">'Start making the submission before fine-tuning'</span><span class="p">)</span>

<span class="n">y_test</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">([</span><span class="n">test_data</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">1024</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">sample_submission</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">"./input/sample_submission.csv"</span><span class="p">)</span> <span class="c"># yk</span>
<span class="n">sample_submission</span><span class="p">[</span><span class="n">list_classes</span><span class="p">]</span> <span class="o">=</span> <span class="n">y_test</span>

<span class="n">sample_submission</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s">'</span><span class="si">%.4</span><span class="s">f_'</span><span class="o">%</span><span class="p">(</span><span class="n">bst_val_score</span><span class="p">)</span><span class="o">+</span><span class="n">STAMP</span><span class="o">+</span><span class="s">'.csv'</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Start making the submission before fine-tuning
153164/153164 [==============================] - 21s 134us/step
</code></pre></div></div>


        
      </section>

      <footer class="page__meta">
        
        
  


  
  
  

  <p class="page__taxonomy">
    <strong><i class="fas fa-fw fa-tags" aria-hidden="true"></i> 태그: </strong>
    <span itemprop="keywords">
    
      
      
      <a href="/tags/#lstm" class="page__taxonomy-item" rel="tag">LSTM</a><span class="sep">, </span>
    
      
      
      <a href="/tags/#python" class="page__taxonomy-item" rel="tag">Python</a>
    
    </span>
  </p>




  


  
  
  

  <p class="page__taxonomy">
    <strong><i class="fas fa-fw fa-folder-open" aria-hidden="true"></i> 카테고리: </strong>
    <span itemprop="keywords">
    
      
      
      <a href="/categories/#data-analysis" class="page__taxonomy-item" rel="tag">Data Analysis</a>
    
    </span>
  </p>


        
          <p class="page__date"><strong><i class="fas fa-fw fa-calendar-alt" aria-hidden="true"></i> 업데이트:</strong> <time datetime="2018-03-07T00:00:00+09:00">March 07, 2018</time></p>
        
      </footer>

      

      
  <nav class="pagination">
    
      <a href="/data%20analysis/feature_selection/" class="pagination--pager" title="정규화를 통한 Feature Selection
">이전</a>
    
    
      <a href="/writing/4th-human/" class="pagination--pager" title="4차 인간
">다음</a>
    
  </nav>

    </div>

    
  </article>

  
  
    <div class="page__related">
      <h4 class="page__related-title">참고</h4>
      <div class="grid__wrapper">
        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="http://schema.org/CreativeWork">
    
    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="/kaggle_kernel/" rel="permalink">Kaggle_kernel
</a>
      
    </h2>
    
    <p class="archive__item-excerpt" itemprop="description">
</p>
  </article>
</div>
        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="http://schema.org/CreativeWork">
    
    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="/writing/sapiens_nongup/" rel="permalink">사피엔스 필사2_농업혁명
</a>
      
    </h2>
    
    <p class="archive__item-excerpt" itemprop="description">사피엔스 제 2장. 농업혁명 관련 필사
(손 필사… 힘들다… ;;)
  












</p>
  </article>
</div>
        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="http://schema.org/CreativeWork">
    
    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="/writing/thougts/" rel="permalink">감옥으로부터의 사색 중에서
</a>
      
    </h2>
    
    <p class="archive__item-excerpt" itemprop="description">
  없는 사람이 살기는 겨울보다 여름이 낫다고 하지만 교도소의 우리들은 없이 살기는 더합니다만 차라리 겨울을 택합니다. 왜냐하면 여름 징역의 열 가지 스무 가지 장점을 일시에 무색케 해버리는 결정적인 사실 ― 여름 징역은 자기의 바로 옆사람을 증오하게 한다는 사실 때문입니다.

...</p>
  </article>
</div>
        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="http://schema.org/CreativeWork">
    
    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="/data%20analysis/Toxic_Preprocessing/" rel="permalink">Kaggle Toxic Classification (2) Preprocessing
</a>
      
    </h2>
    
    <p class="archive__item-excerpt" itemprop="description">Toxic Comment Classification Kaggle 대회 : 링크

</p>
  </article>
</div>
        
      </div>
    </div>
  
  
</div>
    </div>

    
      <div class="search-content">
        <div class="search-content__inner-wrap">
  <input type="text" id="search" class="search-input" tabindex="-1" placeholder="Enter your search term..." />
  <div id="results" class="results"></div>
</div>
      </div>
    

    <div class="page__footer">
      <footer>
        <!-- start custom footer snippets -->

<!-- end custom footer snippets -->
        <div class="page__footer-follow">
  <ul class="social-icons">
    
      <li><strong>팔로우:</strong></li>
    
    
    
    
      <li><a href="https://github.com/InspiringPeople"><i class="fab fa-fw fa-github" aria-hidden="true"></i> GitHub</a></li>
    
    
	
      <li><a href="https://youtube.com/dearpiano"><i class="fab fa-fw fa-youtube" aria-hidden="true"></i> youtube</a></li>
    
    
    <li><a href="/feed.xml"><i class="fas fa-fw fa-rss-square" aria-hidden="true"></i> 피드</a></li>
  </ul>
</div>

<div class="page__footer-copyright">&copy; 2018 YounKyung Jang. Powered by <a href="https://jekyllrb.com" rel="nofollow">Jekyll</a> &amp; <a href="https://mademistakes.com/work/minimal-mistakes-jekyll-theme/" rel="nofollow">Minimal Mistakes</a>.</div>


      </footer>
    </div>

    
  <script src="/assets/js/main.min.js"></script>
  <script src="https://use.fontawesome.com/releases/v5.1.0/js/all.js"></script>




<script src="/assets/js/lunr/lunr.min.js"></script>
<script src="/assets/js/lunr/lunr-store.js"></script>
<script src="/assets/js/lunr/lunr-en.js"></script>




  <script type="text/javascript">
  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-121538180-1']);
  
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();
</script>





    
  <script>
    var disqus_config = function () {
      this.page.url = "http://localhost:4000/data%20analysis/lstm_attention/";  // Replace PAGE_URL with your page's canonical URL variable
      this.page.identifier = "/data%20analysis/lstm_attention"; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
    };
    (function() { // DON'T EDIT BELOW THIS LINE
      var d = document, s = d.createElement('script');
      s.src = 'https://https-inspiringpeople-github-io.disqus.com/embed.js';
      s.setAttribute('data-timestamp', +new Date());
      (d.head || d.body).appendChild(s);
    })();
  </script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>


  



  </body>
</html>